{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13494579,"sourceType":"datasetVersion","datasetId":8567878}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers accelerate torch pandas tqdm --quiet\n\nimport torch\nimport pandas as pd\nfrom itertools import combinations\nfrom tqdm import tqdm\nfrom transformers import LongformerTokenizerFast, LongformerForSequenceClassification","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:44:02.617096Z","iopub.execute_input":"2025-11-05T14:44:02.617324Z","iopub.status.idle":"2025-11-05T14:45:45.120776Z","shell.execute_reply.started":"2025-11-05T14:44:02.617297Z","shell.execute_reply":"2025-11-05T14:45:45.120082Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# 1. CONFIGURATION\n# =========================================================\nMODEL_PATH = \"allenai/longformer-base-4096\"  # ✅ Public, works without login\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nBATCH_SIZE = 8   # Adjust this depending on GPU memory (T4: 4–8 works fine)\n\nprint(f\"Using device: {DEVICE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:45:49.389491Z","iopub.execute_input":"2025-11-05T14:45:49.389791Z","iopub.status.idle":"2025-11-05T14:45:49.395015Z","shell.execute_reply.started":"2025-11-05T14:45:49.389771Z","shell.execute_reply":"2025-11-05T14:45:49.394077Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# 2. LOAD MODEL AND TOKENIZER\n# =========================================================\ntokenizer = LongformerTokenizerFast.from_pretrained(MODEL_PATH)\nmodel = LongformerForSequenceClassification.from_pretrained(\n    MODEL_PATH, num_labels=3  # entailment / neutral / contradiction\n)\nmodel.to(DEVICE)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:45:52.577020Z","iopub.execute_input":"2025-11-05T14:45:52.577311Z","iopub.status.idle":"2025-11-05T14:46:04.818294Z","shell.execute_reply.started":"2025-11-05T14:45:52.577292Z","shell.execute_reply":"2025-11-05T14:46:04.817470Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# 3. LOAD DATA\n# =========================================================\nfile_path =\"/kaggle/input/vidhikaryafinal/vidhikarya_relevant_columns.csv\"  # your actual path\ndf = pd.read_csv(file_path)\n\n# Make sure column names match\nQUESTION_COL = \"question\"\nANSWERS_COL = \"updated_answers\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:46:18.174346Z","iopub.execute_input":"2025-11-05T14:46:18.175021Z","iopub.status.idle":"2025-11-05T14:46:19.954097Z","shell.execute_reply.started":"2025-11-05T14:46:18.174995Z","shell.execute_reply":"2025-11-05T14:46:19.953283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# 4. HELPER FUNCTION\n# =========================================================\ndef predict_contradictions(text_pairs):\n    \"\"\"Batch process text pairs through the model.\"\"\"\n    inputs = tokenizer(\n        [f\"{a1} [SEP] {a2}\" for a1, a2 in text_pairs],\n        return_tensors=\"pt\",\n        padding=True,\n        truncation=True,\n        max_length=4096\n    ).to(DEVICE)\n\n    with torch.no_grad():\n        outputs = model(**inputs).logits\n        preds = torch.argmax(outputs, dim=1).cpu().tolist()\n\n    # Label mapping assumption: 2 = contradiction\n    return [p == 2 for p in preds]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:46:21.724581Z","iopub.execute_input":"2025-11-05T14:46:21.724879Z","iopub.status.idle":"2025-11-05T14:46:21.730082Z","shell.execute_reply.started":"2025-11-05T14:46:21.724858Z","shell.execute_reply":"2025-11-05T14:46:21.729341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# 5. MAIN LOOP\n# =========================================================\ncontradiction_flags = []\n\nfor _, row in tqdm(df.iterrows(), total=len(df)):\n    answers = str(row[ANSWERS_COL]).split(\"|||\")\n    answers = [a.strip() for a in answers if a.strip()]\n\n    # Generate all possible answer pairs\n    pairs = list(combinations(answers, 2))\n\n    if not pairs:\n        contradiction_flags.append(False)\n        continue\n\n    # Batch predict\n    is_contradicting = False\n    for i in range(0, len(pairs), BATCH_SIZE):\n        batch_pairs = pairs[i:i+BATCH_SIZE]\n        preds = predict_contradictions(batch_pairs)\n        if any(preds):\n            is_contradicting = True\n            break\n\n    contradiction_flags.append(is_contradicting)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T14:46:24.904810Z","iopub.execute_input":"2025-11-05T14:46:24.905645Z","iopub.status.idle":"2025-11-05T16:12:21.044213Z","shell.execute_reply.started":"2025-11-05T14:46:24.905613Z","shell.execute_reply":"2025-11-05T16:12:21.043567Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# 6. SAVE RESULTS\n# =========================================================\ndf[\"contradicting\"] = contradiction_flags\ndf.to_csv(\"/kaggle/working/legal_qa_with_flags.csv\", index=False)\nprint(\"✅ Done! Results saved to /kaggle/working/legal_qa_with_flags.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T16:15:25.221329Z","iopub.execute_input":"2025-11-05T16:15:25.222061Z","iopub.status.idle":"2025-11-05T16:15:27.136232Z","shell.execute_reply.started":"2025-11-05T16:15:25.222039Z","shell.execute_reply":"2025-11-05T16:15:27.135423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}