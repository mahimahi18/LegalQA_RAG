{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgSbIJ59QO_S",
        "outputId": "221949a8-302d-4c4b-fdf1-2b8b5d255a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading classifier...\n",
            "Classifier loaded successfully.\n",
            "\n",
            "========================================\n",
            "ðŸš€ Running Research-Inspired Classifier...\n",
            "----------------------------------------\n",
            "Answer 1 Prediction: ACTIONABLE\n",
            "Scores: {'actionable_score': 33, 'informative_score': 0}\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple\n",
        "import subprocess\n",
        "\n",
        "# =============================================================================\n",
        "# DATA STRUCTURE\n",
        "# =============================================================================\n",
        "@dataclass\n",
        "class ExtractedFeatures:\n",
        "    \"\"\"Container for pre-extracted features from your pipeline.\"\"\"\n",
        "    entities: List[str]  # From LLM extraction\n",
        "    key_phrases: List[str]  # From KeyBERT\n",
        "    text: str  # Original answer text\n",
        "\n",
        "# =============================================================================\n",
        "# LINGUISTIC HEURISTIC CLASSIFIER (FIXED)\n",
        "# =============================================================================\n",
        "\n",
        "class ResearchInspiredClassifier:\n",
        "    \"\"\"\n",
        "    Classifies answers using grammatical rules from spaCy.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            self.nlp = spacy.load('en_core_web_sm')\n",
        "        except:\n",
        "            print(\"Downloading spaCy model 'en_core_web_sm'...\")\n",
        "            subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"],\n",
        "                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            self.nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "        self.sequential_markers = {'first', 'second', 'then', 'next', 'finally', 'subsequently'}\n",
        "        self.second_person_pronouns = {'you', 'your', 'yours'}\n",
        "\n",
        "    def predict(self, extracted: ExtractedFeatures) -> Tuple[str, Dict[str, int]]:\n",
        "        \"\"\"\n",
        "        Predicts if an answer is actionable or informative based on\n",
        "        grammatical analysis.\n",
        "        \"\"\"\n",
        "\n",
        "        scores = {\n",
        "            \"actionable_score\": 0,\n",
        "            \"informative_score\": 0\n",
        "        }\n",
        "\n",
        "        # --- 1. Analyze Key Phrases (for Action Verbs) ---\n",
        "        for phrase in extracted.key_phrases:\n",
        "            doc = self.nlp(phrase)\n",
        "            # *** FIX IS HERE ***\n",
        "            # We get the list of sentences, get the first one, and find its root.\n",
        "            sents = list(doc.sents)\n",
        "            if sents: # Make sure we have a sentence\n",
        "                root = sents[0].root\n",
        "                if root.pos_ == 'VERB':\n",
        "                    scores[\"actionable_score\"] += 1\n",
        "\n",
        "        # --- 2. Analyze Entities (for Noun Types) ---\n",
        "        for entity in extracted.entities:\n",
        "            doc = self.nlp(entity)\n",
        "            # *** FIX IS HERE ***\n",
        "            sents = list(doc.sents)\n",
        "            if sents: # Make sure we have a sentence\n",
        "                root = sents[0].root\n",
        "                if root.pos_ == 'PROPN':\n",
        "                    scores[\"informative_score\"] += 1\n",
        "                elif root.pos_ == 'NOUN':\n",
        "                    scores[\"actionable_score\"] += 1\n",
        "\n",
        "        # --- 3. Analyze Full Text for Linguistic Cues ---\n",
        "        doc = self.nlp(extracted.text)\n",
        "        text_lower = extracted.text.lower()\n",
        "\n",
        "        for token in doc:\n",
        "            # A) Check for Modal Verbs (must, should, can, etc.)\n",
        "            if token.tag_ == 'MD':\n",
        "                scores[\"actionable_score\"] += 1\n",
        "\n",
        "            # B) Check for Second-Person Pronouns (you, your)\n",
        "            if token.lower_ in self.second_person_pronouns:\n",
        "                scores[\"actionable_score\"] += 1\n",
        "\n",
        "            # C) Check for Imperative Verbs (Commands)\n",
        "            if token.pos_ == 'VERB' and token.dep_ == 'ROOT' and token.tag_ == 'VB':\n",
        "                has_subject = any(child.dep_ in ['nsubj', 'nsubjpass'] for child in token.children)\n",
        "                if not has_subject:\n",
        "                    scores[\"actionable_score\"] += 1\n",
        "\n",
        "            # D) Check for Actionable Infinitives (e.g., \"to file\")\n",
        "            if token.lower_ == 'to' and token.dep_ == 'aux':\n",
        "                if token.head.pos_ == 'VERB':\n",
        "                    scores[\"actionable_score\"] += 1\n",
        "\n",
        "        # E) Check for Sequential Markers (first, then, next)\n",
        "        for marker in self.sequential_markers:\n",
        "            if marker in text_lower:\n",
        "                scores[\"actionable_score\"] += 1\n",
        "\n",
        "        # --- 4. Make the final decision ---\n",
        "        if scores[\"actionable_score\"] > scores[\"informative_score\"]:\n",
        "            label = \"actionable\"\n",
        "        else:\n",
        "            label = \"informative\"\n",
        "\n",
        "        return label, scores\n",
        "\n",
        "# =============================================================================\n",
        "# EXAMPLE USAGE (HOW TO RUN IT)\n",
        "# =============================================================================\n",
        "\n",
        "# 1. Instantiate the classifier\n",
        "print(\"Loading classifier...\")\n",
        "classifier = ResearchInspiredClassifier()\n",
        "print(\"Classifier loaded successfully.\")\n",
        "\n",
        "# 2. Your sample data\n",
        "sample1 = ExtractedFeatures(\n",
        "        entities=['ews category reservations', 'residential plot', 'residential flat', 'ews reservation', 'family definition', 'agricultural land', 'gross annual income', 'ews certificate', 'general candidate'],\n",
        "        key_phrases=['eligible ews certificate satisfy', 'seeks benefit reservation parents', 'rs lakhs includes', 'land property owned', 'conditions general', 'family gross annual', 'reservations definition', 'different locations clubbed checking', '18', 'dear client'],\n",
        "        text=\"\"\"Dear Client,To be eligible for the EWS certificate, you will have to satisfy all the following conditions: 1) You should be a â€˜generalâ€™ candidate (not covered under reservation for SC, ST, or OBC). 2) Your familyâ€™s gross annual income should be below Rs. 8 lakhs. This includes income from all sources such as agriculture, salary, business, etc., for the financial year before you apply for the exam., 3) Your family should not own agricultural land of size 5 acres or more. 4) Your family should not own a residential flat of an area of 1000 square feet or more. 5) Your family should not own a residential plot (in notified municipalities) of an area of 100 square yards or more. 6) Your family should not own a residential plot (other than in notified municipalities) of an area of 200 square yards or more. The land or property owned by the family in different locations should be clubbed while checking the eligibility conditions for EWS category reservations. The definition of Family in EWS reservation means the person who seeks the benefit of reservation, his/her parents and siblings below the age of 18 years, as also his/her spouse and children below the age of 18 years. So, given the conditions of eligibility and the definition of family, when your family owns a residential flat of more than an area of 1000 sq. feet, even if it is in the name of your deceased father, you may not be considered for the issue of EWS certificate.\"\"\"\n",
        "    )\n",
        "\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"ðŸš€ Running Research-Inspired Classifier...\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# --- Process Answer 1 ---\n",
        "label1, scores1 = classifier.predict(sample1)\n",
        "print(f\"Answer 1 Prediction: {label1.upper()}\")\n",
        "print(f\"Scores: {scores1}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple\n",
        "import subprocess\n",
        "import re # We'll use regex to find list items\n",
        "\n",
        "# =============================================================================\n",
        "# DATA STRUCTURE\n",
        "# =============================================================================\n",
        "@dataclass\n",
        "class ExtractedFeatures:\n",
        "    \"\"\"Container for pre-extracted features from your pipeline.\"\"\"\n",
        "    entities: List[str]  # From LLM extraction\n",
        "    key_phrases: List[str]  # From KeyBERT\n",
        "    text: str  # Original answer text\n",
        "\n",
        "# =============================================================================\n",
        "# IMPROVISED LINGUISTIC HEURISTIC V3 (With Weights & Balancing)\n",
        "# =============================================================================\n",
        "\n",
        "class ImprovisedClassifier:\n",
        "    \"\"\"\n",
        "    Improves the heuristic with weights and balancing rules.\n",
        "    It's less \"trigger-happy\" on actionable cues and better\n",
        "    at spotting informative text.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            self.nlp = spacy.load('en_core_web_sm')\n",
        "        except:\n",
        "            print(\"Downloading spaCy model 'en_core_web_sm'...\")\n",
        "            subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"],\n",
        "                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            self.nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "        # --- Define our grammatical markers ---\n",
        "        self.sequential_markers = {'first', 'second', 'then', 'next', 'finally', 'subsequently'}\n",
        "        self.second_person_pronouns = {'you', 'your', 'yours'}\n",
        "\n",
        "        # NEW: Markers for informative text to balance the score\n",
        "        self.explanatory_markers = {\n",
        "            'because', 'since', 'due to', 'under', 'pursuant',\n",
        "            'whereas', 'states that', 'means', 'definition of', 'refers to',\n",
        "            'in the case of', 'as per'\n",
        "        }\n",
        "\n",
        "        # NEW: Weights to make some rules stronger than others\n",
        "        self.weights = {\n",
        "            \"verb_phrase\": 1.0,         # A verb phrase is a decent signal\n",
        "            \"propn_entity\": 1.5,        # A proper noun (Act, Court) is a strong info signal\n",
        "            # \"noun_entity\" is REMOVED. It was buggy and mis-ID'ing things.\n",
        "\n",
        "            # --- Text Weights ---\n",
        "            \"modal_verb\": 1.0,          # \"should\", \"must\" are strong...\n",
        "            \"second_person\": 0.5,       # ...but \"you\" is a weak signal (it's in all text)\n",
        "            \"imperative_cmd\": 3.0,      # A direct command is a HUGE action signal\n",
        "            \"action_infinitive\": 1.5,   # \"to file\" is a good action signal\n",
        "            \"sequential_marker\": 1.5,   # \"first...\" is a good action signal\n",
        "\n",
        "            # --- Balancing Weights ---\n",
        "            \"explanatory_marker\": 1.5,  # \"because...\" is a strong info signal\n",
        "            \"list_marker\": 2.5          # \"1)\" is a VERY strong info signal (the \"EWS fix\")\n",
        "        }\n",
        "\n",
        "    def predict(self, extracted: ExtractedFeatures) -> Tuple[str, Dict[str, float]]:\n",
        "        \"\"\"\n",
        "        Predicts using a weighted, balanced scoring system.\n",
        "        \"\"\"\n",
        "\n",
        "        scores = {\n",
        "            \"actionable_score\": 0.0,\n",
        "            \"informative_score\": 0.0\n",
        "        }\n",
        "\n",
        "        # --- 1. Analyze Key Phrases ---\n",
        "        for phrase in extracted.key_phrases:\n",
        "            doc = self.nlp(phrase)\n",
        "            sents = list(doc.sents)\n",
        "            if sents:\n",
        "                root = sents[0].root\n",
        "                if root.pos_ == 'VERB':\n",
        "                    scores[\"actionable_score\"] += self.weights['verb_phrase']\n",
        "\n",
        "        # --- 2. Analyze Entities ---\n",
        "        for entity in extracted.entities:\n",
        "            doc = self.nlp(entity)\n",
        "            # This is a better rule: if ANY part of the entity is a Proper Noun,\n",
        "            # it's informative (e.g., \"EWS certificate\", \"Industrial Act\")\n",
        "            if any(token.pos_ == 'PROPN' for token in doc):\n",
        "                scores[\"informative_score\"] += self.weights['propn_entity']\n",
        "            # We removed the 'NOUN' rule because it was wrong (e.g., \"certificate\")\n",
        "\n",
        "        # --- 3. Analyze Full Text ---\n",
        "        doc = self.nlp(extracted.text)\n",
        "        text_lower = extracted.text.lower()\n",
        "\n",
        "        # A) Check for list items (THE \"EWS FIX\")\n",
        "        # Looks for \"1)\", \"2)\", \"(a)\", \"(b)\", etc.\n",
        "        list_items = re.findall(r'\\b[0-9a-z][.)]', text_lower)\n",
        "        if list_items:\n",
        "            # Add a big bonus for each list item found\n",
        "            scores[\"informative_score\"] += (len(list_items) * self.weights['list_marker'])\n",
        "\n",
        "        # B) Check for explanatory markers\n",
        "        for marker in self.explanatory_markers:\n",
        "            if marker in text_lower:\n",
        "                scores[\"informative_score\"] += self.weights['explanatory_marker']\n",
        "\n",
        "        # C) Check for standard actionable cues\n",
        "        for token in doc:\n",
        "            if token.tag_ == 'MD':\n",
        "                scores[\"actionable_score\"] += self.weights['modal_verb']\n",
        "            if token.lower_ in self.second_person_pronouns:\n",
        "                scores[\"actionable_score\"] += self.weights['second_person']\n",
        "            if token.pos_ == 'VERB' and token.dep_ == 'ROOT' and token.tag_ == 'VB':\n",
        "                has_subject = any(child.dep_ in ['nsubj', 'nsubjpass'] for child in token.children)\n",
        "                if not has_subject:\n",
        "                    scores[\"actionable_score\"] += self.weights['imperative_cmd']\n",
        "            if token.lower_ == 'to' and token.dep_ == 'aux':\n",
        "                if token.head.pos_ == 'VERB':\n",
        "                    scores[\"actionable_score\"] += self.weights['action_infinitive']\n",
        "\n",
        "        for marker in self.sequential_markers:\n",
        "            if marker in text_lower:\n",
        "                scores[\"actionable_score\"] += self.weights['sequential_marker']\n",
        "\n",
        "        # --- 4. Make the final decision ---\n",
        "        if scores[\"actionable_score\"] > scores[\"informative_score\"]:\n",
        "            label = \"actionable\"\n",
        "        else:\n",
        "            label = \"informative\"\n",
        "\n",
        "        # Round scores for clean output\n",
        "        scores[\"actionable_score\"] = round(scores[\"actionable_score\"], 2)\n",
        "        scores[\"informative_score\"] = round(scores[\"informative_score\"], 2)\n",
        "\n",
        "        return label, scores\n",
        "\n",
        "# =============================================================================\n",
        "# EXAMPLE USAGE (Running the problematic text)\n",
        "# =============================================================================\n",
        "\n",
        "# 1. Instantiate the classifier\n",
        "print(\"Loading classifier...\")\n",
        "classifier = ImprovisedClassifier()\n",
        "print(\"Classifier loaded successfully.\")\n",
        "\n",
        "# 2. Your problematic EWS sample\n",
        "sample1 = ExtractedFeatures(\n",
        "        entities=['ews category reservations', 'residential plot', 'residential flat', 'ews reservation', 'family definition', 'agricultural land', 'gross annual income', 'ews certificate', 'general candidate'],\n",
        "        key_phrases=['eligible ews certificate satisfy', 'seeks benefit reservation parents', 'rs lakhs includes', 'land property owned', 'conditions general', 'family gross annual', 'reservations definition', 'different locations clubbed checking', '18', 'dear client'],\n",
        "        text=\"\"\"Dear Client,To be eligible for the EWS certificate, you will have to satisfy all the following conditions: 1) You should be a â€˜generalâ€™ candidate (not covered under reservation for SC, ST, or OBC). 2) Your familyâ€™s gross annual income should be below Rs. 8 lakhs. This includes income from all sources such as agriculture, salary, business, etc., for the financial year before you apply for the exam., 3) Your family should not own agricultural land of size 5 acres or more. 4) Your family should not own a residential flat of an area of 1000 square feet or more. 5) Your family should not own a residential plot (in notified municipalities) of an area of 100 square yards or more. 6) Your family should not own a residential plot (other than in notified municipalities) of an area of 200 square yards or more. The land or property owned by the family in different locations should be clubbed while checking the eligibility conditions for EWS category reservations. The definition of Family in EWS reservation means the person who seeks the benefit of reservation, his/her parents and siblings below the age of 18 years, as also his/her spouse and children below the age of 18 years. So, given the conditions of eligibility and the definition of family, when your family owns a residential flat of more than an area of 1000 sq. feet, even if it is in the name of your deceased father, you may not be considered for the issue of EWS certificate.\"\"\"\n",
        "    )\n",
        "\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"ðŸš€ Running Improvised Classifier V3...\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# --- Process Answer 1 ---\n",
        "label1, scores1 = classifier.predict(sample1)\n",
        "print(f\"Prediction: {label1.upper()}\")\n",
        "print(f\"Scores: {scores1}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"ðŸš€ Running on a clearly ACTIONABLE text...\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# 3. A clearly actionable sample\n",
        "sample2 = ExtractedFeatures(\n",
        "    entities=['Advocate', 'Labour Commissioner', 'Civil Court'],\n",
        "    key_phrases=['file a civil suit', 'raise an industrial dispute', 'consult an Advocate'],\n",
        "    text=\"\"\"...In that scenario, the terminated employee serving a legal notice to the employer can raise an industrial dispute before the concerned Labour Commissioner. Otherwise, he has to file a civil suit before the Civil Court. If required, consult an Advocate experienced in service matters.\"\"\"\n",
        ")\n",
        "\n",
        "# --- Process Answer 2 ---\n",
        "label2, scores2 = classifier.predict(sample2)\n",
        "print(f\"Prediction: {label2.upper()}\")\n",
        "print(f\"Scores: {scores2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXsxRunYX0-H",
        "outputId": "9f3a9e9f-dfcb-47f4-eb83-e0e8c3ce4413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading classifier...\n",
            "Classifier loaded successfully.\n",
            "\n",
            "========================================\n",
            "ðŸš€ Running Improvised Classifier V3...\n",
            "----------------------------------------\n",
            "Prediction: ACTIONABLE\n",
            "Scores: {'actionable_score': 20.0, 'informative_score': 19.5}\n",
            "\n",
            "========================================\n",
            "ðŸš€ Running on a clearly ACTIONABLE text...\n",
            "----------------------------------------\n",
            "Prediction: ACTIONABLE\n",
            "Scores: {'actionable_score': 8.5, 'informative_score': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cl Robust\n",
        "import spacy\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "# =============================================================================\n",
        "# DATA STRUCTURE\n",
        "# =============================================================================\n",
        "@dataclass\n",
        "class ExtractedFeatures:\n",
        "    \"\"\"Container for pre-extracted features from your pipeline.\"\"\"\n",
        "    entities: List[str]  # From LLM extraction\n",
        "    key_phrases: List[str]  # From KeyBERT\n",
        "    text: str  # Original answer text\n",
        "\n",
        "# =============================================================================\n",
        "# IMPROVED LINGUISTIC HEURISTIC CLASSIFIER\n",
        "# =============================================================================\n",
        "\n",
        "class ImprovedResearchInspiredClassifier:\n",
        "    \"\"\"\n",
        "    Classifies answers using grammatical rules from spaCy with better balance\n",
        "    between informative and actionable signals.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            self.nlp = spacy.load('en_core_web_sm')\n",
        "        except:\n",
        "            print(\"Downloading spaCy model 'en_core_web_sm'...\")\n",
        "            subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"],\n",
        "                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            self.nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "        # Actionable markers\n",
        "        self.sequential_markers = {'first', 'second', 'then', 'next', 'finally', 'subsequently', 'lastly'}\n",
        "        self.second_person_pronouns = {'you', 'your', 'yours', 'yourself'}\n",
        "        self.action_verbs = {'apply', 'file', 'submit', 'contact', 'visit', 'obtain', 'provide',\n",
        "                            'ensure', 'check', 'verify', 'prepare', 'complete', 'sign'}\n",
        "\n",
        "        # Informative markers\n",
        "        self.legal_terms = {'act', 'section', 'clause', 'article', 'amendment', 'statute',\n",
        "                           'regulation', 'ordinance', 'provision', 'code', 'law', 'rule',\n",
        "                           'subsection', 'paragraph', 'schedule', 'chapter'}\n",
        "        self.citation_patterns = [\n",
        "            r'\\b(section|sec\\.?|s\\.?)\\s*\\d+',  # Section 123\n",
        "            r'\\b(article|art\\.?)\\s*\\d+',        # Article 45\n",
        "            r'\\b\\d{4}\\s*act\\b',                  # 2020 Act\n",
        "            r'\\b[A-Z]{2,}\\s+Act\\b',             # Income Tax Act\n",
        "            r'\\bvs?\\.?\\s+[A-Z]',                # Case citations (A vs B)\n",
        "        ]\n",
        "\n",
        "    def _count_legal_citations(self, text: str) -> int:\n",
        "        \"\"\"Count legal citations and references in text.\"\"\"\n",
        "        count = 0\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Count legal terms\n",
        "        for term in self.legal_terms:\n",
        "            count += len(re.findall(r'\\b' + term + r'\\b', text_lower))\n",
        "\n",
        "        # Count citation patterns\n",
        "        for pattern in self.citation_patterns:\n",
        "            count += len(re.findall(pattern, text, re.IGNORECASE))\n",
        "\n",
        "        return count\n",
        "\n",
        "    def _analyze_sentence_types(self, doc) -> Dict[str, int]:\n",
        "        \"\"\"Analyze types of sentences in the text.\"\"\"\n",
        "        sentence_types = {\n",
        "            'imperative': 0,      # Commands\n",
        "            'declarative': 0,     # Statements\n",
        "            'interrogative': 0    # Questions\n",
        "        }\n",
        "\n",
        "        for sent in doc.sents:\n",
        "            sent_text = sent.text.strip()\n",
        "            root = sent.root\n",
        "\n",
        "            # Check for questions\n",
        "            if sent_text.endswith('?'):\n",
        "                sentence_types['interrogative'] += 1\n",
        "            # Check for imperatives (commands)\n",
        "            elif root.pos_ == 'VERB' and root.tag_ == 'VB':\n",
        "                has_subject = any(child.dep_ in ['nsubj', 'nsubjpass'] for child in root.children)\n",
        "                if not has_subject:\n",
        "                    sentence_types['imperative'] += 1\n",
        "            else:\n",
        "                sentence_types['declarative'] += 1\n",
        "\n",
        "        return sentence_types\n",
        "\n",
        "    def _calculate_informative_density(self, doc, text: str) -> float:\n",
        "        \"\"\"\n",
        "        Calculate density of informative content:\n",
        "        - Legal terms per 100 words\n",
        "        - Proper nouns (laws, acts, organizations)\n",
        "        - Numbers (amounts, sections, years)\n",
        "        \"\"\"\n",
        "        word_count = len([token for token in doc if not token.is_punct and not token.is_space])\n",
        "        if word_count == 0:\n",
        "            return 0\n",
        "\n",
        "        # Count legal citations\n",
        "        legal_count = self._count_legal_citations(text)\n",
        "\n",
        "        # Count proper nouns (excluding \"you\", \"client\" etc)\n",
        "        propn_count = sum(1 for token in doc if token.pos_ == 'PROPN' and\n",
        "                         token.lower_ not in {'client', 'sir', 'madam'})\n",
        "\n",
        "        # Count numbers (potentially section numbers, amounts, dates)\n",
        "        num_count = sum(1 for token in doc if token.pos_ == 'NUM' or\n",
        "                       token.like_num or re.match(r'\\d+', token.text))\n",
        "\n",
        "        # Density per 100 words\n",
        "        density = ((legal_count * 3) + (propn_count * 2) + num_count) / word_count * 100\n",
        "        return density\n",
        "\n",
        "    def _calculate_actionable_density(self, doc, text: str) -> float:\n",
        "        \"\"\"\n",
        "        Calculate density of actionable content:\n",
        "        - Imperative verbs\n",
        "        - Modal verbs\n",
        "        - Second person pronouns\n",
        "        - Action verbs\n",
        "        \"\"\"\n",
        "        word_count = len([token for token in doc if not token.is_punct and not token.is_space])\n",
        "        if word_count == 0:\n",
        "            return 0\n",
        "\n",
        "        action_count = 0\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        for token in doc:\n",
        "            # Modal verbs (should, must, can)\n",
        "            if token.tag_ == 'MD':\n",
        "                action_count += 2  # Weight modals more\n",
        "\n",
        "            # Second person pronouns\n",
        "            if token.lower_ in self.second_person_pronouns:\n",
        "                action_count += 1\n",
        "\n",
        "            # Action verbs from our list\n",
        "            if token.lemma_ in self.action_verbs:\n",
        "                action_count += 2\n",
        "\n",
        "            # Imperatives\n",
        "            if token.pos_ == 'VERB' and token.dep_ == 'ROOT' and token.tag_ == 'VB':\n",
        "                has_subject = any(child.dep_ in ['nsubj', 'nsubjpass'] for child in token.children)\n",
        "                if not has_subject:\n",
        "                    action_count += 2\n",
        "\n",
        "        # Sequential markers\n",
        "        for marker in self.sequential_markers:\n",
        "            if marker in text_lower:\n",
        "                action_count += 1\n",
        "\n",
        "        # Density per 100 words\n",
        "        density = action_count / word_count * 100\n",
        "        return density\n",
        "\n",
        "    def predict(self, extracted: ExtractedFeatures) -> Tuple[str, Dict[str, float]]:\n",
        "        \"\"\"\n",
        "        Predicts if an answer is actionable or informative based on\n",
        "        improved grammatical and content analysis.\n",
        "        \"\"\"\n",
        "        doc = self.nlp(extracted.text)\n",
        "\n",
        "        # Calculate densities\n",
        "        informative_density = self._calculate_informative_density(doc, extracted.text)\n",
        "        actionable_density = self._calculate_actionable_density(doc, extracted.text)\n",
        "\n",
        "        # Analyze sentence types\n",
        "        sentence_types = self._analyze_sentence_types(doc)\n",
        "        total_sentences = sum(sentence_types.values())\n",
        "\n",
        "        # Calculate ratios\n",
        "        imperative_ratio = sentence_types['imperative'] / total_sentences if total_sentences > 0 else 0\n",
        "        declarative_ratio = sentence_types['declarative'] / total_sentences if total_sentences > 0 else 0\n",
        "\n",
        "        # Analyze entities for legal content\n",
        "        entity_legal_score = 0\n",
        "        for entity in extracted.entities:\n",
        "            entity_lower = entity.lower()\n",
        "            # Check if entity contains legal terms\n",
        "            if any(term in entity_lower for term in self.legal_terms):\n",
        "                entity_legal_score += 1\n",
        "\n",
        "        # Calculate final scores with weighted factors\n",
        "        scores = {\n",
        "            \"informative_score\": (\n",
        "                informative_density * 2.0 +           # Legal citations are strong signal\n",
        "                declarative_ratio * 20 +              # Declarative sentences suggest informative\n",
        "                entity_legal_score * 5                # Legal entities\n",
        "            ),\n",
        "            \"actionable_score\": (\n",
        "                actionable_density * 1.5 +            # Action markers\n",
        "                imperative_ratio * 30                 # Imperative sentences are strong signal\n",
        "            ),\n",
        "            # Additional breakdown for debugging\n",
        "            \"informative_density\": round(informative_density, 2),\n",
        "            \"actionable_density\": round(actionable_density, 2),\n",
        "            \"imperative_ratio\": round(imperative_ratio, 2),\n",
        "            \"declarative_ratio\": round(declarative_ratio, 2),\n",
        "            \"legal_citations\": self._count_legal_citations(extracted.text),\n",
        "            \"entity_legal_score\": entity_legal_score\n",
        "        }\n",
        "\n",
        "        # Make decision with threshold\n",
        "        # If scores are close, prefer informative (legal content is default)\n",
        "        threshold = 1.2  # Actionable must be 20% higher to win\n",
        "        if scores[\"actionable_score\"] > scores[\"informative_score\"] * threshold:\n",
        "            label = \"actionable\"\n",
        "        else:\n",
        "            label = \"informative\"\n",
        "\n",
        "        return label, scores\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Instantiate the classifier\n",
        "    print(\"Loading improved classifier...\")\n",
        "    classifier = ImprovedResearchInspiredClassifier()\n",
        "    print(\"Classifier loaded successfully.\\n\")\n",
        "\n",
        "    # 2. Example 1\n",
        "    sample1 = ExtractedFeatures(\n",
        "        entities=['abnormal loss', 'recovery of amount', 'claim amount', 'legal notice', 'file a suit'],\n",
        "        key_phrases=['left job intimation caused', 'sir issue legal', 'abnormal loss company', 'claim', 'recovery', 'reasonable file', 'left', 'dear sir', 'intimation', 'said'],\n",
        "        text=\"\"\"Dear Sir,You may it issue a legal notice to both of them informing them that they have left the job without intimation and caused abnormal loss to the company and you may claim any amount which is reasonable and thereafter file a suit for recovery of said amount.\"\"\"\n",
        "    )\n",
        "\n",
        "    # Example 2: More clearly informative (with legal citations)\n",
        "    sample2 = ExtractedFeatures(\n",
        "        entities=['Section 498A', 'Indian Penal Code', 'Supreme Court', 'dowry harassment'],\n",
        "        key_phrases=['section 498a ipc', 'supreme court ruling', 'cognizable offence',\n",
        "                    'non-bailable', 'matrimonial cruelty'],\n",
        "        text=\"\"\"Section 498A of the Indian Penal Code deals with cruelty by husband or relatives of husband. According to this provision, whoever, being the husband or the relative of the husband of a woman, subjects such woman to cruelty shall be punished with imprisonment which may extend to three years and shall also be liable to fine. The Supreme Court in Rajesh vs State of Haryana (2013) has clarified the scope of this section. It is a cognizable and non-bailable offence. The term 'cruelty' has been defined under the Explanation to include harassment for dowry demands.\"\"\"\n",
        "    )\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ðŸš€ Testing Improved Classifier\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # --- Process Answer 1 (Should be more actionable) ---\n",
        "    print(\"\\nðŸ“„ ANSWER 1 (EWS Certificate Eligibility):\")\n",
        "    print(\"-\" * 60)\n",
        "    label1, scores1 = classifier.predict(sample1)\n",
        "    print(f\"Prediction: {label1.upper()}\")\n",
        "    print(f\"\\nDetailed Scores:\")\n",
        "    for key, value in scores1.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    # --- Process Answer 2 (Should be informative) ---\n",
        "    print(\"\\n\\nðŸ“„ ANSWER 2 (Section 498A Explanation):\")\n",
        "    print(\"-\" * 60)\n",
        "    label2, scores2 = classifier.predict(sample2)\n",
        "    print(f\"Prediction: {label2.upper()}\")\n",
        "    print(f\"\\nDetailed Scores:\")\n",
        "    for key, value in scores2.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ1rpM1qNZf0",
        "outputId": "4ee1da06-0873-491c-dfeb-7081aea7a7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading improved classifier...\n",
            "Classifier loaded successfully.\n",
            "\n",
            "============================================================\n",
            "ðŸš€ Testing Improved Classifier\n",
            "============================================================\n",
            "\n",
            "ðŸ“„ ANSWER 1 (EWS Certificate Eligibility):\n",
            "------------------------------------------------------------\n",
            "Prediction: ACTIONABLE\n",
            "\n",
            "Detailed Scores:\n",
            "  informative_score: 8.16326530612245\n",
            "  actionable_score: 24.48979591836735\n",
            "  informative_density: 4.08\n",
            "  actionable_density: 16.33\n",
            "  imperative_ratio: 0\n",
            "  declarative_ratio: 0\n",
            "  legal_citations: 0\n",
            "  entity_legal_score: 0\n",
            "\n",
            "\n",
            "ðŸ“„ ANSWER 2 (Section 498A Explanation):\n",
            "------------------------------------------------------------\n",
            "Prediction: INFORMATIVE\n",
            "\n",
            "Detailed Scores:\n",
            "  informative_score: 119.58333333333334\n",
            "  actionable_score: 9.375\n",
            "  informative_density: 44.79\n",
            "  actionable_density: 6.25\n",
            "  imperative_ratio: 0.0\n",
            "  declarative_ratio: 1.0\n",
            "  legal_citations: 6\n",
            "  entity_legal_score: 2\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cl Robust heuristic- THIS IS THE LATEST. USE THIS.\n",
        "import spacy\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "@dataclass\n",
        "class ExtractedFeatures:\n",
        "    entities: List[str]\n",
        "    key_phrases: List[str]\n",
        "    text: str\n",
        "\n",
        "\n",
        "class ImprovedResearchInspiredClassifier:\n",
        "\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            self.nlp = spacy.load('en_core_web_sm')\n",
        "        except:\n",
        "            print(\"Downloading spaCy model 'en_core_web_sm'...\")\n",
        "            subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"],\n",
        "                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            self.nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "        # Actionable markers\n",
        "        self.sequential_markers = {'first', 'second', 'then', 'next', 'finally', 'subsequently', 'lastly'}\n",
        "        self.second_person_pronouns = {'you', 'your', 'yours', 'yourself'}\n",
        "        self.action_verbs = {'apply', 'file', 'submit', 'contact', 'visit', 'obtain', 'provide',\n",
        "                            'ensure', 'check', 'verify', 'prepare', 'complete', 'sign'}\n",
        "\n",
        "        # Informative markers\n",
        "        self.legal_terms = {'act', 'section', 'clause', 'article', 'amendment', 'statute',\n",
        "                           'regulation', 'ordinance', 'provision', 'code', 'law', 'rule',\n",
        "                           'subsection', 'paragraph', 'schedule', 'chapter'}\n",
        "        self.citation_patterns = [\n",
        "            r'\\b(section|sec\\.?|s\\.?)\\s*\\d+',  #  examples: Section 123\n",
        "            r'\\b(article|art\\.?)\\s*\\d+',        # Article 45\n",
        "            r'\\b\\d{4}\\s*act\\b',                  # 2020 Act\n",
        "            r'\\b[A-Z]{2,}\\s+Act\\b',             # Income Tax Act\n",
        "            r'\\bvs?\\.?\\s+[A-Z]',                # Case citations (A vs B)\n",
        "        ]\n",
        "\n",
        "    def _count_legal_citations(self, text: str) -> int:\n",
        "        \"\"\"Count legal citations and references in text.\"\"\"\n",
        "        count = 0\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Count legal terms\n",
        "        for term in self.legal_terms:\n",
        "            count += len(re.findall(r'\\b' + term + r'\\b', text_lower))\n",
        "\n",
        "        # Count citation patterns\n",
        "        for pattern in self.citation_patterns:\n",
        "            count += len(re.findall(pattern, text, re.IGNORECASE))\n",
        "\n",
        "        return count\n",
        "\n",
        "    def _analyze_sentence_types(self, doc) -> Dict[str, int]:\n",
        "        \"\"\"Analyze types of sentences in the text.\"\"\"\n",
        "        sentence_types = {\n",
        "            'imperative': 0,\n",
        "            'declarative': 0,\n",
        "            'interrogative': 0\n",
        "        }\n",
        "\n",
        "        for sent in doc.sents:\n",
        "            sent_text = sent.text.strip()\n",
        "            root = sent.root\n",
        "\n",
        "            # Check for questions\n",
        "            if sent_text.endswith('?'):\n",
        "                sentence_types['interrogative'] += 1\n",
        "            # Check for imperatives (commands)\n",
        "            elif root.pos_ == 'VERB' and root.tag_ == 'VB':\n",
        "                has_subject = any(child.dep_ in ['nsubj', 'nsubjpass'] for child in root.children)\n",
        "                if not has_subject:\n",
        "                    sentence_types['imperative'] += 1\n",
        "            else:\n",
        "                sentence_types['declarative'] += 1\n",
        "\n",
        "        return sentence_types\n",
        "\n",
        "    def _calculate_informative_density(self, doc, text: str) -> float:\n",
        "\n",
        "        word_count = len([token for token in doc if not token.is_punct and not token.is_space])\n",
        "        if word_count == 0:\n",
        "            return 0\n",
        "\n",
        "        # Count legal citations\n",
        "        legal_count = self._count_legal_citations(text)\n",
        "\n",
        "        # Count proper nouns (excluding \"you\", \"client\" etc)\n",
        "        propn_count = sum(1 for token in doc if token.pos_ == 'PROPN' and\n",
        "                         token.lower_ not in {'client', 'sir', 'madam'})\n",
        "\n",
        "        # Count numbers (potentially section numbers, amounts, dates)\n",
        "        num_count = sum(1 for token in doc if token.pos_ == 'NUM' or\n",
        "                       token.like_num or re.match(r'\\d+', token.text))\n",
        "\n",
        "        # Density per 100 words\n",
        "        density = ((legal_count * 3) + (propn_count * 2) + num_count) / word_count * 100\n",
        "        return density\n",
        "\n",
        "    def _calculate_actionable_density(self, doc, text: str) -> float:\n",
        "\n",
        "        word_count = len([token for token in doc if not token.is_punct and not token.is_space])\n",
        "        if word_count == 0:\n",
        "            return 0\n",
        "\n",
        "        action_count = 0\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        for token in doc:\n",
        "            # Modal verbs (should, must, can)\n",
        "            if token.tag_ == 'MD':\n",
        "                action_count += 2  # Weight modals more\n",
        "\n",
        "            # Second person pronouns\n",
        "            if token.lower_ in self.second_person_pronouns:\n",
        "                action_count += 1\n",
        "\n",
        "            # Action verbs from our list\n",
        "            if token.lemma_ in self.action_verbs:\n",
        "                action_count += 2\n",
        "\n",
        "            # Imperatives\n",
        "            if token.pos_ == 'VERB' and token.dep_ == 'ROOT' and token.tag_ == 'VB':\n",
        "                has_subject = any(child.dep_ in ['nsubj', 'nsubjpass'] for child in token.children)\n",
        "                if not has_subject:\n",
        "                    action_count += 2\n",
        "\n",
        "        # Sequential markers\n",
        "        for marker in self.sequential_markers:\n",
        "            if marker in text_lower:\n",
        "                action_count += 1\n",
        "\n",
        "        # Density per 100 words\n",
        "        density = action_count / word_count * 100\n",
        "        return density\n",
        "\n",
        "    def predict(self, extracted: ExtractedFeatures) -> Tuple[str, Dict[str, float]]:\n",
        "        \"\"\"\n",
        "        Predicts if an answer is actionable or informative based on\n",
        "        improved grammatical and content analysis.\n",
        "        \"\"\"\n",
        "        doc = self.nlp(extracted.text)\n",
        "\n",
        "        # Calculate densities\n",
        "        informative_density = self._calculate_informative_density(doc, extracted.text)\n",
        "        actionable_density = self._calculate_actionable_density(doc, extracted.text)\n",
        "\n",
        "        # Analyze sentence types\n",
        "        sentence_types = self._analyze_sentence_types(doc)\n",
        "        total_sentences = sum(sentence_types.values())\n",
        "\n",
        "        # Calculate ratios\n",
        "        imperative_ratio = sentence_types['imperative'] / total_sentences if total_sentences > 0 else 0\n",
        "        declarative_ratio = sentence_types['declarative'] / total_sentences if total_sentences > 0 else 0\n",
        "\n",
        "        # Analyze entities for legal content\n",
        "        entity_legal_score = 0\n",
        "        for entity in extracted.entities:\n",
        "            entity_lower = entity.lower()\n",
        "            # Check if entity contains legal terms\n",
        "            if any(term in entity_lower for term in self.legal_terms):\n",
        "                entity_legal_score += 1\n",
        "\n",
        "\n",
        "        scores = {\n",
        "            \"informative_score\": (\n",
        "                informative_density * 2.0 +\n",
        "                declarative_ratio * 20 +\n",
        "                entity_legal_score * 5\n",
        "            ),\n",
        "            \"actionable_score\": (\n",
        "                actionable_density * 1.5 +\n",
        "                imperative_ratio * 30\n",
        "            ),\n",
        "\n",
        "            \"informative_density\": round(informative_density, 2),\n",
        "            \"actionable_density\": round(actionable_density, 2),\n",
        "            \"imperative_ratio\": round(imperative_ratio, 2),\n",
        "            \"declarative_ratio\": round(declarative_ratio, 2),\n",
        "            \"legal_citations\": self._count_legal_citations(extracted.text),\n",
        "            \"entity_legal_score\": entity_legal_score\n",
        "        }\n",
        "\n",
        "\n",
        "        threshold = 1.2  # Actionable must be 20% higher to win\n",
        "        if scores[\"actionable_score\"] > scores[\"informative_score\"] * threshold:\n",
        "            label = \"actionable\"\n",
        "        else:\n",
        "            label = \"informative\"\n",
        "\n",
        "        return label, scores\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"Loading improved classifier...\")\n",
        "    classifier = ImprovedResearchInspiredClassifier()\n",
        "    print(\"Classifier loaded successfully.\\n\")\n",
        "\n",
        "\n",
        "    sample1 = ExtractedFeatures(\n",
        "        entities=['ews category reservations', 'residential plot', 'residential flat',\n",
        "                 'ews reservation', 'family definition', 'agricultural land',\n",
        "                 'gross annual income', 'ews certificate', 'general candidate'],\n",
        "        key_phrases=['eligible ews certificate satisfy', 'seeks benefit reservation parents',\n",
        "                    'rs lakhs includes', 'land property owned', 'conditions general',\n",
        "                    'family gross annual', 'reservations definition',\n",
        "                    'different locations clubbed checking', '18', 'dear client'],\n",
        "        text=\"\"\"Dear Client,To be eligible for the EWS certificate, you will have to satisfy all the following conditions: 1) You should be a 'general' candidate (not covered under reservation for SC, ST, or OBC). 2) Your family's gross annual income should be below Rs. 8 lakhs. This includes income from all sources such as agriculture, salary, business, etc., for the financial year before you apply for the exam., 3) Your family should not own agricultural land of size 5 acres or more. 4) Your family should not own a residential flat of an area of 1000 square feet or more. 5) Your family should not own a residential plot (in notified municipalities) of an area of 100 square yards or more. 6) Your family should not own a residential plot (other than in notified municipalities) of an area of 200 square yards or more. The land or property owned by the family in different locations should be clubbed while checking the eligibility conditions for EWS category reservations. The definition of Family in EWS reservation means the person who seeks the benefit of reservation, his/her parents and siblings below the age of 18 years, as also his/her spouse and children below the age of 18 years. So, given the conditions of eligibility and the definition of family, when your family owns a residential flat of more than an area of 1000 sq. feet, even if it is in the name of your deceased father, you may not be considered for the issue of EWS certificate.\"\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "    sample2 = ExtractedFeatures(\n",
        "        entities=['abnormal loss', 'recovery of amount', 'claim amount', 'legal notice', 'file a suit'],\n",
        "        key_phrases=['left job intimation caused', 'sir issue legal', 'abnormal loss company', 'claim', 'recovery', 'reasonable file', 'left', 'dear sir', 'intimation', 'said'],\n",
        "        text=\"\"\"Dear Sir,You may it issue a legal notice to both of them informing them that they have left the job without intimation and caused abnormal loss to the company and you may claim any amount which is reasonable and thereafter file a suit for recovery of said amount.\"\"\"\n",
        "    )\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\" Testing Improved Classifier\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    print(\"\\n ANSWER 1:\")\n",
        "    print(\"-\" * 60)\n",
        "    label1, scores1 = classifier.predict(sample1)\n",
        "    print(f\"Prediction: {label1.upper()}\")\n",
        "    print(f\"\\nDetailed Scores:\")\n",
        "    for key, value in scores1.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    print(\"\\n\\n ANSWER 2:\")\n",
        "    print(\"-\" * 60)\n",
        "    label2, scores2 = classifier.predict(sample2)\n",
        "    print(f\"Prediction: {label2.upper()}\")\n",
        "    print(f\"\\nDetailed Scores:\")\n",
        "    for key, value in scores2.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yB6G1IdONUH",
        "outputId": "b9a2152d-4b65-4374-aa3b-7e1af162bb95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading improved classifier...\n",
            "Classifier loaded successfully.\n",
            "\n",
            "============================================================\n",
            " Testing Improved Classifier\n",
            "============================================================\n",
            "\n",
            " ANSWER 1:\n",
            "------------------------------------------------------------\n",
            "Prediction: INFORMATIVE\n",
            "\n",
            "Detailed Scores:\n",
            "  informative_score: 48.01556420233463\n",
            "  actionable_score: 19.260700389105057\n",
            "  informative_density: 14.01\n",
            "  actionable_density: 12.84\n",
            "  imperative_ratio: 0.0\n",
            "  declarative_ratio: 1.0\n",
            "  legal_citations: 0\n",
            "  entity_legal_score: 0\n",
            "\n",
            "\n",
            " ANSWER 2:\n",
            "------------------------------------------------------------\n",
            "Prediction: ACTIONABLE\n",
            "\n",
            "Detailed Scores:\n",
            "  informative_score: 8.16326530612245\n",
            "  actionable_score: 24.48979591836735\n",
            "  informative_density: 4.08\n",
            "  actionable_density: 16.33\n",
            "  imperative_ratio: 0\n",
            "  declarative_ratio: 0\n",
            "  legal_citations: 0\n",
            "  entity_legal_score: 0\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Trying on the entire dataset and standardizing values\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "import ast\n",
        "import subprocess\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Any\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# --- PART 1: SETUP ---\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "except:\n",
        "    print(\"Drive already mounted or running locally.\")\n",
        "\n",
        "# --- PART 2: SCORING LOGIC (PRESERVED & ADAPTED) ---\n",
        "class RobustClassifier:\n",
        "    def __init__(self):\n",
        "        # Load spaCy for sentence structure analysis (imperative vs declarative)\n",
        "        try:\n",
        "            self.nlp = spacy.load('en_core_web_sm')\n",
        "        except:\n",
        "            print(\"Downloading spaCy model...\")\n",
        "            subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"],\n",
        "                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            self.nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "        # Actionable markers (Identical to original script)\n",
        "        self.sequential_markers = {'first', 'second', 'then', 'next', 'finally', 'subsequently', 'lastly'}\n",
        "        self.second_person_pronouns = {'you', 'your', 'yours', 'yourself'}\n",
        "        self.action_verbs = {'apply', 'file', 'submit', 'contact', 'visit', 'obtain', 'provide',\n",
        "                            'ensure', 'check', 'verify', 'prepare', 'complete', 'sign', 'consult', 'appeal'}\n",
        "\n",
        "        # Informative markers (Identical to original script)\n",
        "        self.legal_terms = {'act', 'section', 'clause', 'article', 'amendment', 'statute',\n",
        "                           'regulation', 'ordinance', 'provision', 'code', 'law', 'rule',\n",
        "                           'subsection', 'paragraph', 'schedule', 'chapter', 'court', 'tribunal'}\n",
        "\n",
        "        self.citation_patterns = [\n",
        "            r'\\b(section|sec\\.?|s\\.?)\\s*\\d+', r'\\b(article|art\\.?)\\s*\\d+',\n",
        "            r'\\b\\d{4}\\s*act\\b', r'\\b[A-Z]{2,}\\s+Act\\b', r'\\bvs?\\.?\\s+[A-Z]',\n",
        "        ]\n",
        "\n",
        "    def _analyze_sentence_types(self, doc) -> Dict[str, int]:\n",
        "        sentence_types = {'imperative': 0, 'declarative': 0, 'interrogative': 0}\n",
        "        for sent in doc.sents:\n",
        "            sent_text = sent.text.strip()\n",
        "            root = sent.root\n",
        "            if sent_text.endswith('?'):\n",
        "                sentence_types['interrogative'] += 1\n",
        "            elif root.pos_ == 'VERB' and root.tag_ == 'VB':\n",
        "                has_subject = any(child.dep_ in ['nsubj', 'nsubjpass'] for child in root.children)\n",
        "                if not has_subject:\n",
        "                    sentence_types['imperative'] += 1\n",
        "            else:\n",
        "                sentence_types['declarative'] += 1\n",
        "        return sentence_types\n",
        "\n",
        "    def normalize_score(self, raw_score: float) -> int:\n",
        "        # Heuristic scaling to map density values to 0-100\n",
        "        scaled = raw_score * 1.6\n",
        "        return int(min(scaled, 100))\n",
        "\n",
        "    def predict(self, text: str, extracted_entities: List[str]) -> str:\n",
        "        doc = self.nlp(text)\n",
        "        word_count = len([t for t in doc if not t.is_punct and not t.is_space])\n",
        "        if word_count == 0: return \"Inf:0/Act:0\"\n",
        "\n",
        "        # --- 1. INFORMATIVE SCORE CALCULATION ---\n",
        "        # Logic: (Legal Citations * 3) + (Extracted Entities * 2) + (Numbers)\n",
        "\n",
        "        # A. Count Legal Citations in Text (Regex)\n",
        "        legal_citation_count = 0\n",
        "        for pattern in self.citation_patterns:\n",
        "            legal_citation_count += len(re.findall(pattern, text, re.IGNORECASE))\n",
        "\n",
        "        # B. Count Provided Entities (from Columns F & H)\n",
        "        # We trust the extracted features instead of guessing with spaCy PROPN\n",
        "        entity_count = len(extracted_entities)\n",
        "\n",
        "        # C. Count Numbers\n",
        "        num_count = sum(1 for token in doc if token.like_num or token.pos_ == 'NUM')\n",
        "\n",
        "        # Density Math\n",
        "        inf_density = ((legal_citation_count * 3) + (entity_count * 2) + num_count) / word_count * 100\n",
        "\n",
        "        # Check if entities contain legal terms for bonus\n",
        "        entity_legal_score = sum(1 for e in extracted_entities if any(t in e.lower() for t in self.legal_terms))\n",
        "\n",
        "        # --- 2. ACTIONABLE SCORE CALCULATION ---\n",
        "        # Logic: Modals + Second Person + Action Verbs + Imperatives\n",
        "\n",
        "        action_count = 0\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        for token in doc:\n",
        "            if token.tag_ == 'MD': action_count += 2 # Modals (must/should)\n",
        "            if token.lower_ in self.second_person_pronouns: action_count += 1\n",
        "            if token.lemma_ in self.action_verbs: action_count += 2\n",
        "\n",
        "        # Check sequential markers in text\n",
        "        for marker in self.sequential_markers:\n",
        "            if marker in text_lower: action_count += 1\n",
        "\n",
        "        act_density = action_count / word_count * 100\n",
        "\n",
        "        # --- 3. SENTENCE STRUCTURE ---\n",
        "        st = self._analyze_sentence_types(doc)\n",
        "        total_sent = sum(st.values())\n",
        "        imp_ratio = st['imperative'] / total_sent if total_sent > 0 else 0\n",
        "        dec_ratio = st['declarative'] / total_sent if total_sent > 0 else 0\n",
        "\n",
        "        # --- 4. FINAL SCORING (THE ORIGINAL FORMULA) ---\n",
        "\n",
        "        raw_inf_score = (inf_density * 2.0) + (dec_ratio * 20) + (entity_legal_score * 5)\n",
        "        raw_act_score = (act_density * 1.5) + (imp_ratio * 30)\n",
        "\n",
        "        final_inf = self.normalize_score(raw_inf_score)\n",
        "        final_act = self.normalize_score(raw_act_score)\n",
        "\n",
        "        return f\"Inf:{final_inf} | Act:{final_act}\"\n",
        "\n",
        "# --- PART 3: FILE PROCESSING ---\n",
        "\n",
        "def parse_clean_list(cell_content):\n",
        "    \"\"\"Parses the dirty string cells from Columns F and H into clean lists.\"\"\"\n",
        "    if pd.isna(cell_content): return []\n",
        "    s = str(cell_content)\n",
        "    # Remove the stats \"Precision: ...\"\n",
        "    s = re.sub(r'(Precision|Recall|F1-Score).*', '', s, flags=re.DOTALL | re.IGNORECASE).strip()\n",
        "    # Extract text inside single quotes\n",
        "    items = re.findall(r\"'([^']*)'\", s)\n",
        "    return items\n",
        "\n",
        "def run_pipeline():\n",
        "    # 1. Define Paths\n",
        "    folder_path = \"/content/drive/MyDrive\"\n",
        "    input_filename = \"Compare different Entity Extraction.xlsx\"\n",
        "    output_filename = \"Compare different Entity Extraction_SCORED.xlsx\"\n",
        "\n",
        "    input_path = os.path.join(folder_path, input_filename)\n",
        "    output_path = os.path.join(folder_path, output_filename)\n",
        "\n",
        "    print(f\"Reading file: {input_path}\")\n",
        "    try:\n",
        "        df = pd.read_excel(input_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file: {e}\")\n",
        "        print(\"Make sure you added the shortcut to 'My Drive'!\")\n",
        "        return\n",
        "\n",
        "    # 2. Handle S.NO Merged Cells (The User's Requirement)\n",
        "    if 'S.NO' in df.columns:\n",
        "        df['S.NO'] = df['S.NO'].ffill()\n",
        "\n",
        "    classifier = RobustClassifier()\n",
        "    scores = []\n",
        "\n",
        "    print(\"Processing rows...\")\n",
        "\n",
        "    # 3. Iterate Rows\n",
        "    for index, row in df.iterrows():\n",
        "\n",
        "        # Extract Data\n",
        "        # We use .get() or column names. Assuming names match the screenshot.\n",
        "        answer = str(row['Answer']) if not pd.isna(row['Answer']) else \"\"\n",
        "\n",
        "        # Combine Entity (Col F) and KeyPhrases (Col H) for the \"Entity Count\"\n",
        "        col_f = row['(Entity + Fact) Extraction by LLM']\n",
        "        col_h = row['Key-Phrases Extraction (using KeyBERT)']\n",
        "\n",
        "        entities_f = parse_clean_list(col_f)\n",
        "        entities_h = parse_clean_list(col_h)\n",
        "        all_entities = list(set(entities_f + entities_h)) # Unique list\n",
        "\n",
        "        # 4. Handle \"||\" split inside the answer column\n",
        "        # Even if S.NO splits rows, specific cells might still have splits.\n",
        "        if \"||\" in answer:\n",
        "            split_answers = answer.split(\"||\")\n",
        "            split_scores = []\n",
        "            for sub_ans in split_answers:\n",
        "                if len(sub_ans.strip()) < 3: continue\n",
        "                sc = classifier.predict(sub_ans.strip(), all_entities)\n",
        "                split_scores.append(sc)\n",
        "            scores.append(\" || \".join(split_scores))\n",
        "        else:\n",
        "            # Standard single row processing\n",
        "            if len(answer) < 3:\n",
        "                scores.append(\"Inf:0 | Act:0\")\n",
        "            else:\n",
        "                sc = classifier.predict(answer, all_entities)\n",
        "                scores.append(sc)\n",
        "\n",
        "    # 5. Save\n",
        "    df['Automated_Scores'] = scores\n",
        "    df.to_excel(output_path, index=False)\n",
        "    print(f\"Done. File saved to: {output_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T387Q4ZmzZR8",
        "outputId": "8f03c735-4ec5-4f8c-becb-490a60c326a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Reading file: /content/drive/MyDrive/Compare different Entity Extraction.xlsx\n",
            "Processing rows...\n",
            "Done. File saved to: /content/drive/MyDrive/Compare different Entity Extraction_SCORED.xlsx\n"
          ]
        }
      ]
    }
  ]
}